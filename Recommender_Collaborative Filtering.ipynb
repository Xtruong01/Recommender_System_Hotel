{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_768\\892665658.py\", line 6, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\pandas\\__init__.py\", line 39, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_768\\892665658.py\", line 6, in <module>\n",
      "    import pandas as pd\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"c:\\Program Files\\Python310\\lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# from surprise import SVD, SVDpp, NMF, Dataset, Reader\n",
    "# from surprise.model_selection import cross_validate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_768\\2474371650.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  als_data['Hotel ID'] = als_data['Hotel ID'].apply(lambda x: int(x.split('_')[1]))\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_768\\2474371650.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  als_data['Reviewer ID'] = als_data['Reviewer ID'].apply(lambda x: int(x.split('_')[2]))\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo Spark session\n",
    "spark = SparkSession.builder.appName(\"CollaborativeFiltering\").getOrCreate()\n",
    "\n",
    "# Đọc dữ liệu\n",
    "hotel_comments_df = pd.read_csv(\"data/hotel_comments_cleaned.csv\")\n",
    "hotel_info_df = pd.read_csv(\"data/hotel_info_cleaned.csv\")\n",
    "\n",
    "# Tiền xử lý dữ liệu cho mô hình PySpark ALS\n",
    "als_data = hotel_comments_df[['Hotel ID', 'Reviewer ID', 'Score']]\n",
    "als_data['Hotel ID'] = als_data['Hotel ID'].apply(lambda x: int(x.split('_')[1]))\n",
    "als_data['Reviewer ID'] = als_data['Reviewer ID'].apply(lambda x: int(x.split('_')[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi DataFrame sang Spark DataFrame\n",
    "spark_df = spark.createDataFrame(als_data)\n",
    "\n",
    "# Chia dữ liệu thành tập đào tạo và kiểm tra\n",
    "(training, test) = spark_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Xây dựng mô hình ALS\n",
    "als = ALS(maxIter=10, regParam=0.1, rank=25, userCol=\"Reviewer ID\", itemCol=\"Hotel ID\", ratingCol=\"Score\", coldStartStrategy=\"drop\", nonnegative=True)\n",
    "model_als = als.fit(training)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25892"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviewers = spark_df.select(\"Reviewer ID\").distinct().count()\n",
    "hotels = spark_df.select(\"Hotel ID\").distinct().count()\n",
    "numerator = spark_df.count()\n",
    "display(numerator, reviewers, hotels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.9802580836483332\n",
      "+--------+-----------+-----+----------+\n",
      "|Hotel ID|Reviewer ID|Score|prediction|\n",
      "+--------+-----------+-----+----------+\n",
      "|      19|        148|  9.2|  8.978996|\n",
      "|      10|         31|  8.0|  8.842883|\n",
      "|      17|         31|  8.8|  9.182246|\n",
      "|      22|         31|  7.6|  9.227229|\n",
      "|       1|         85| 10.0|   9.21325|\n",
      "+--------+-----------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình\n",
    "predictions = model_als.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Score\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error = {rmse}\")\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu mô hình sử dụng PySpark API\n",
    "model_als.save(\"als_model_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tải dữ liệu cho Surprise\n",
    "# reader = Reader(rating_scale=(1, 10))\n",
    "# data = Dataset.load_from_df(hotel_comments_df[['Reviewer ID', 'Hotel ID', 'Score']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Huấn luyện và đánh giá mô hình SVD\n",
    "# svd = SVD()\n",
    "# svd_results = cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Huấn luyện và đánh giá mô hình SVD++\n",
    "# svdpp = SVDpp()\n",
    "# svdpp_results = cross_validate(svdpp, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Huấn luyện và đánh giá mô hình NMF\n",
    "# nmf = NMF()\n",
    "# nmf_results = cross_validate(nmf, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVD có RMSE trung bình là khoảng 0.9456 và MAE trung bình là 0.7589. Thời gian fit và test khá nhanh, chỉ khoảng 0.22s và 0.02s tương ứng.\n",
    "- SVD++ cho thấy RMSE trung bình là khoảng 0.9477 và MAE trung bình là 0.7662. Thời gian fit và test là 0.16s và 0.01s tương ứng.\n",
    "- NMF cho kết quả RMSE trung bình là 0.9766 và MAE trung bình là 0.7942. Thời gian fit của mô hình này lâu nhất là 0.86s, nhưng thời gian test tương tự như hai mô hình còn lại.\n",
    "\n",
    "=> Mô hình SVD là một lựa chọn phù hợp cho bài toán này, nhờ vào sự cân bằng giữa độ chính xác và thời gian huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Xử dụng mô hình SVD để xây dựng hàm đề xuất\n",
    "\n",
    "# # Chuẩn bị dữ liệu\n",
    "# reader = Reader(rating_scale=(1, 10))\n",
    "# data = Dataset.load_from_df(hotel_comments_df[['Reviewer ID', 'Hotel ID', 'Score']], reader)\n",
    "# trainset = data.build_full_trainset()\n",
    "\n",
    "# # Huấn luyện mô hình SVD\n",
    "# svd_model = SVD()\n",
    "# svd_model.fit(trainset)\n",
    "\n",
    "# def recommend_hotels(reviewer_id, num_recommendations=5):\n",
    "#     # Lấy danh sách tất cả các khách sạn\n",
    "#     all_hotels = hotel_info_df['Hotel_ID'].unique()\n",
    "    \n",
    "#     # Lấy danh sách các khách sạn đã đánh giá bởi người dùng này\n",
    "#     rated_hotels = hotel_comments_df[hotel_comments_df['Reviewer ID'] == reviewer_id]['Hotel ID'].unique()\n",
    "    \n",
    "#     # Lọc ra các khách sạn chưa được đánh giá bởi người dùng này\n",
    "#     unrated_hotels = [hotel for hotel in all_hotels if hotel not in rated_hotels]\n",
    "    \n",
    "#     # Dự đoán điểm cho các khách sạn chưa được đánh giá\n",
    "#     predictions = [svd_model.predict(reviewer_id, hotel).est for hotel in unrated_hotels]\n",
    "    \n",
    "#     # Tạo DataFrame chứa kết quả và sắp xếp theo điểm dự đoán\n",
    "#     recommendations = pd.DataFrame({\n",
    "#         'Hotel_ID': unrated_hotels,\n",
    "#         'Predicted_Score': predictions\n",
    "#     })\n",
    "    \n",
    "#     # Lấy top các khách sạn được đề xuất cao nhất\n",
    "#     top_recommendations = recommendations.sort_values(by='Predicted_Score', ascending=False).head(num_recommendations)\n",
    "    \n",
    "#     # Trả về thông tin chi tiết của các khách sạn được đề xuất\n",
    "#     return hotel_info_df[hotel_info_df['Hotel_ID'].isin(top_recommendations['Hotel_ID'])][['Hotel_ID', 'Hotel_Name', 'Hotel_Rank', 'Hotel_Address', 'Total_Score']]\n",
    "\n",
    "# # Ví dụ sử dụng hàm\n",
    "# print(recommend_hotels(reviewer_id='148', num_recommendations=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Lấy ma trận user và item factors\n",
    "user_factors = model_als.userFactors.toPandas()\n",
    "item_factors = model_als.itemFactors.toPandas()\n",
    "\n",
    "# Lưu các factors này vào một file pkl\n",
    "with open('als_model_factors.pkl', 'wb') as f:\n",
    "    pickle.dump((user_factors, item_factors), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
